我们提出了一个概念上简单、灵活和通用的用于目标实例分割（object instance segmentation）的框架。我们的方法能够有效地检测图像中的目标，同时还能为每个实例生成一个高质量的分割掩码（segmentation mask）。这个方面被称为 Mask R-CNN，是在 Faster R-CNN 上的扩展——在其已有的用于边界框识别的分支上添加了一个并行的用于预测目标掩码的分支。Mask R-CNN 的训练很简单，仅比 Faster R-CNN 多一点计算开销，运行速度为 5 fps。此外，Mask R-CNN 可以很容易泛化到其它任务，比如，让我们可以在同一个框架中估计人类的姿态。我们在 COCO 难题套件的所有 3 种任务（track）上都得到了最佳结果，其中包括实例分割、边界框目标检测和人物关键点检测（person keypoint detection）。没有使用其它的技巧，Mask R-CNN 的表现超越了在每个任务上所有已有的单个模型，包括 COCO 2016 挑战赛的获胜模型。我们希望我们的简单又有效的方法能成为一个坚实的基础，能帮助简化实例层面识别的未来研究。我们将会公开相关代码。

图 2：在 COCO 测试集上的 Mask R-CNN 结果。这些结果基于 ResNet-101，在 5 fps 的速度下实现了 35.7 的 mask AP。图上不同的颜色表示不同的掩码，另外也给出的边界框、类别和置信度。

图 3：头架构（Head Architecture）：我们延展了两个已有的 Faster R-CNN 头 [14,21]。左图和右图分别展示了 ResNet C4 和 FPN 的主干（backbone）的头（head），分别来自 [14] 和 [21]，可以看到上面还增加了一个 mask 分支。图中的数字表示空间分辨率和信道，箭头表示卷积（conv）、去卷积（deconv）或全连接层（fc），具体可以根据情况推断（卷积会保持空间维度而去卷积会增加它）。除了输出卷积是 1×1 之外，其它所有卷积都是 3×3，去卷积是 2×2，步幅为 2。我们在隐藏层中使用 ReLU [24]。左图中 res5 表示 ResNet 的第 5 阶段，为了简单起见，我们进行了修改，使第 1 个卷积层运行在一个 7×7 RoI 上，步幅为 1（而不是如 [14] 中的 14×14，步幅为 2）。右图中的 ×4 表示 4 个连续卷积的堆叠。

表 1：在 COCO test-dev 上的实例分割 mask AP。MNC [7] 和 FCIS [20] 分别是 COCO 2015 和 2016 分割挑战赛的获胜模型。没有添加其它额外的东西，Mask R-CNN 的表现超过了更复杂的 FCIS+++——其包括多种规模的训练/测试、水平翻转测试和 OHEM [29]。所有的条目都是单个模型的结果。

表 2：Mask R-CNN 的分解。我们是在 trainval35k 上训练的，在 minival 上测试的，除非特别指明都报道的是 mask AP 成绩。

表 3：在 test-dev 上目标检测单个模型的结果（边界框 AP）vs 当前最佳。使用 ResNet-101-FPN 的 Mask R-CNN 的表现超越了所有之前最佳模型的基本变体（在这些实验中忽略了 mask output）。Mask R-CNN 在 [21] 的基础上获得的增益得益于对 RoIAlign (+1.1 APbb)、多任务训练 (+0.9 APbb) 和 ResNeXt-101 (+1.6 APbb) 的使用。

图 6：使用 Mask R-CNN（ResNet-50-FPN）在 COCO 测试上的关键点检测结果，带有来自于同一个模型的人物分割掩码。该模型在 5 fps 条件下实现了 63.1 的关键点 AP。

表 4：在 COCO test-dev 上的关键点检测 AP。我们的 ResNet-50-FPN 是以 5 fps 运行的单个模型。CMUPose+++[4] 是 2016 年的比赛获胜者，其使用了多尺度测试、带有 CPM 的后处理 [33] 和带有一个目标检测器的滤波，累加了约 5 分（在个人通信中阐明的）。† : G-RMI 是在 COCP plus MPII [1]（2.5 万张图像）上训练的，使用了两个模型（Inception-ResNet-v2 + ResNet- 101）。因为它们使用了更多数据，所以这不是与 Mask R-CNN 的直接对比。